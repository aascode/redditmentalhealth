{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Groups by POS+Empath+Subbreddit by Username by adding the values, to put into models.\n",
    "\n",
    "The recall means \"how many of this class you find over the whole number of element of this class\"\n",
    "The precision will be \"how many are correctly classified among that class\"\n",
    "The f1-score is the harmonic mean between precision & recall\n",
    "\n",
    "\n",
    "GaussianNB\n",
    "SGDClassifier- SVM\n",
    "SGDClassifier- LogReg\n",
    "MultinomialNB\n",
    "RandomForestClassifier\n",
    "XGBoost\n",
    "AdaBoost\n",
    "Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('Cap/EmpathVariables_PartsOfSpeech1.csv', delimiter = ',',encoding='utf-8')\n",
    "df=df.drop(['Body'], axis = 1)\n",
    "df['count']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6=df.groupby(['Username','Depressed'])['Subreddit'].apply(lambda x:','.join(x)).reset_index(name ='Subreddits')\n",
    "df6['Subreddits'] = df6['Subreddits'].str.replace('depression,', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(df6.Subreddits)\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=pd.DataFrame(data=X_train_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf= df.groupby(['Username','Depressed']).mean()\n",
    "ddf=ddf.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.concat([ddf, df2], axis=1)\n",
    "df1=df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Username</th>\n",
       "      <th>Depressed</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Subjectivity</th>\n",
       "      <th>Noun Phrases</th>\n",
       "      <th>CC</th>\n",
       "      <th>CD</th>\n",
       "      <th>DT</th>\n",
       "      <th>EX</th>\n",
       "      <th>FW</th>\n",
       "      <th>...</th>\n",
       "      <th>8576</th>\n",
       "      <th>8577</th>\n",
       "      <th>8578</th>\n",
       "      <th>8579</th>\n",
       "      <th>8580</th>\n",
       "      <th>8581</th>\n",
       "      <th>8582</th>\n",
       "      <th>8583</th>\n",
       "      <th>8584</th>\n",
       "      <th>8585</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#NAME?</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.001289</td>\n",
       "      <td>0.285775</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-Chely-</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.059854</td>\n",
       "      <td>0.449464</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-Darth_Revan-</td>\n",
       "      <td>1</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-ExtremeMusic-</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004630</td>\n",
       "      <td>0.322222</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-GrapeGrass-</td>\n",
       "      <td>0</td>\n",
       "      <td>0.116529</td>\n",
       "      <td>0.405958</td>\n",
       "      <td>10.800000</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.440000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 8822 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Username  Depressed  Polarity  Subjectivity  Noun Phrases    CC  \\\n",
       "0          #NAME?          0 -0.001289      0.285775      4.333333  0.00   \n",
       "1         -Chely-          1 -0.059854      0.449464     12.000000  0.00   \n",
       "2   -Darth_Revan-          1  0.007500      0.260000      3.000000  0.00   \n",
       "3  -ExtremeMusic-          0  0.004630      0.322222      2.555556  0.00   \n",
       "4    -GrapeGrass-          0  0.116529      0.405958     10.800000  0.24   \n",
       "\n",
       "         CD        DT   EX   FW  ...  8576  8577  8578  8579  8580  8581  \\\n",
       "0  1.000000  0.041667  0.0  0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "1  4.000000  0.500000  0.0  0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "2  2.000000  0.000000  0.0  0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "3  1.333333  0.000000  0.0  0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "4  2.440000  0.160000  0.0  0.2  ...   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "\n",
       "   8582  8583  8584  8585  \n",
       "0   0.0   0.0   0.0   0.0  \n",
       "1   0.0   0.0   0.0   0.0  \n",
       "2   0.0   0.0   0.0   0.0  \n",
       "3   0.0   0.0   0.0   0.0  \n",
       "4   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 8822 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "decode_map = {0: \"NORMAL\", 1: \"DEPRESSED\"}\n",
    "def decode_sentiment(label):\n",
    "    return decode_map[int(label)]\n",
    "\n",
    "df.Depressed = df.Depressed.apply(lambda x: decode_sentiment(x))\n",
    "df=df.drop(['Username'], axis = 1)\n",
    "df=df.drop(['Depressed'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df, df1.Depressed, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   DEPRESSED       0.56      0.57      0.56       483\n",
      "      NORMAL       0.48      0.46      0.47       413\n",
      "\n",
      "   micro avg       0.52      0.52      0.52       896\n",
      "   macro avg       0.52      0.52      0.52       896\n",
      "weighted avg       0.52      0.52      0.52       896\n",
      "\n",
      "\n",
      "\n",
      "[[277 206]\n",
      " [221 192]]\n",
      "\n",
      "\n",
      "0.5234375\n",
      "0.5562248995983936\n",
      "0.5734989648033126\n",
      "0.564729867482161\n",
      "0.5191950029827701\n",
      "0.03851328499423988\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "clf = DummyClassifier().fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"\\n\")\n",
    "print(metrics.confusion_matrix(y_test, y_pred)) \n",
    "print(\"\\n\")\n",
    "\n",
    "y_test1= [0 if x==\"NORMAL\" else x for x in y_test]\n",
    "y_test1= [1 if x==\"DEPRESSED\" else x for x in y_test1]\n",
    "\n",
    "y_pred= [0 if x==\"NORMAL\" else x for x in y_pred]\n",
    "y_pred= [1 if x==\"DEPRESSED\" else x for x in y_pred]\n",
    "\n",
    "print(metrics.accuracy_score(y_test1, y_pred))            #Accuracy\n",
    "print(precision_score(y_test1, y_pred))                   #Precision\n",
    "print(recall_score(y_test1, y_pred))                      #Recall\n",
    "print(f1_score(y_test1, y_pred))                          #F1 Score\n",
    "print(roc_auc_score(y_test1, y_pred))                     #AUC\n",
    "print(matthews_corrcoef(y_test1, y_pred))                 #MCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   DEPRESSED       0.76      0.80      0.78       483\n",
      "      NORMAL       0.75      0.70      0.73       413\n",
      "\n",
      "   micro avg       0.75      0.75      0.75       896\n",
      "   macro avg       0.75      0.75      0.75       896\n",
      "weighted avg       0.75      0.75      0.75       896\n",
      "\n",
      "\n",
      "\n",
      "[[385  98]\n",
      " [122 291]]\n",
      "\n",
      "\n",
      "0.7544642857142857\n",
      "0.7593688362919132\n",
      "0.7971014492753623\n",
      "0.7777777777777778\n",
      "0.7508509667684318\n",
      "0.5045632154700126\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf = GaussianNB().fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"\\n\")\n",
    "print(metrics.confusion_matrix(y_test, y_pred)) \n",
    "print(\"\\n\")\n",
    "\n",
    "y_test1= [0 if x==\"NORMAL\" else x for x in y_test]\n",
    "y_test1= [1 if x==\"DEPRESSED\" else x for x in y_test1]\n",
    "\n",
    "y_pred= [0 if x==\"NORMAL\" else x for x in y_pred]\n",
    "y_pred= [1 if x==\"DEPRESSED\" else x for x in y_pred]\n",
    "\n",
    "print(metrics.accuracy_score(y_test1, y_pred))            #Accuracy\n",
    "print(precision_score(y_test1, y_pred))                   #Precision\n",
    "print(recall_score(y_test1, y_pred))                      #Recall\n",
    "print(f1_score(y_test1, y_pred))                          #F1 Score\n",
    "print(roc_auc_score(y_test1, y_pred))                     #AUC\n",
    "print(matthews_corrcoef(y_test1, y_pred))                 #MCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   DEPRESSED       0.84      0.86      0.85       483\n",
      "      NORMAL       0.83      0.81      0.82       413\n",
      "\n",
      "   micro avg       0.84      0.84      0.84       896\n",
      "   macro avg       0.84      0.84      0.84       896\n",
      "weighted avg       0.84      0.84      0.84       896\n",
      "\n",
      "\n",
      "\n",
      "[[416  67]\n",
      " [ 78 335]]\n",
      "\n",
      "\n",
      "0.8381696428571429\n",
      "0.8421052631578947\n",
      "0.8612836438923396\n",
      "0.8515864892528147\n",
      "0.8362108292100924\n",
      "0.6739284392379011\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=0).fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"\\n\")\n",
    "print(metrics.confusion_matrix(y_test, y_pred)) \n",
    "print(\"\\n\")\n",
    "\n",
    "y_test1= [0 if x==\"NORMAL\" else x for x in y_test]\n",
    "y_test1= [1 if x==\"DEPRESSED\" else x for x in y_test1]\n",
    "\n",
    "y_pred= [0 if x==\"NORMAL\" else x for x in y_pred]\n",
    "y_pred= [1 if x==\"DEPRESSED\" else x for x in y_pred]\n",
    "\n",
    "print(metrics.accuracy_score(y_test1, y_pred))            #Accuracy\n",
    "print(precision_score(y_test1, y_pred))                   #Precision\n",
    "print(recall_score(y_test1, y_pred))                      #Recall\n",
    "print(f1_score(y_test1, y_pred))                          #F1 Score\n",
    "print(roc_auc_score(y_test1, y_pred))                     #AUC\n",
    "print(matthews_corrcoef(y_test1, y_pred))                 #MCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asus\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   DEPRESSED       0.94      0.79      0.86       483\n",
      "      NORMAL       0.79      0.94      0.86       413\n",
      "\n",
      "   micro avg       0.86      0.86      0.86       896\n",
      "   macro avg       0.87      0.87      0.86       896\n",
      "weighted avg       0.87      0.86      0.86       896\n",
      "\n",
      "\n",
      "\n",
      "[[381 102]\n",
      " [ 23 390]]\n",
      "\n",
      "\n",
      "0.8604910714285714\n",
      "0.943069306930693\n",
      "0.7888198757763976\n",
      "0.8590755355129651\n",
      "0.8665649015685861\n",
      "0.7344398479754317\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "clf = SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, max_iter=5, random_state=42).fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"\\n\")\n",
    "print(metrics.confusion_matrix(y_test, y_pred)) \n",
    "print(\"\\n\")\n",
    "\n",
    "y_test1= [0 if x==\"NORMAL\" else x for x in y_test]\n",
    "y_test1= [1 if x==\"DEPRESSED\" else x for x in y_test1]\n",
    "\n",
    "y_pred= [0 if x==\"NORMAL\" else x for x in y_pred]\n",
    "y_pred= [1 if x==\"DEPRESSED\" else x for x in y_pred]\n",
    "\n",
    "print(metrics.accuracy_score(y_test1, y_pred))            #Accuracy\n",
    "print(precision_score(y_test1, y_pred))                   #Precision\n",
    "print(recall_score(y_test1, y_pred))                      #Recall\n",
    "print(f1_score(y_test1, y_pred))                          #F1 Score\n",
    "print(roc_auc_score(y_test1, y_pred))                     #AUC\n",
    "print(matthews_corrcoef(y_test1, y_pred))                 #MCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asus\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   DEPRESSED       0.92      0.83      0.87       483\n",
      "      NORMAL       0.82      0.91      0.86       413\n",
      "\n",
      "   micro avg       0.87      0.87      0.87       896\n",
      "   macro avg       0.87      0.87      0.87       896\n",
      "weighted avg       0.87      0.87      0.87       896\n",
      "\n",
      "\n",
      "\n",
      "[[401  82]\n",
      " [ 36 377]]\n",
      "\n",
      "\n",
      "0.8683035714285714\n",
      "0.9176201372997712\n",
      "0.8302277432712215\n",
      "0.8717391304347826\n",
      "0.8715303365266519\n",
      "0.7410129649285897\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "clf = SGDClassifier(loss='log', penalty='l2',alpha=1e-3, max_iter=5, random_state=42).fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"\\n\")\n",
    "print(metrics.confusion_matrix(y_test, y_pred)) \n",
    "print(\"\\n\")\n",
    "\n",
    "y_test1= [0 if x==\"NORMAL\" else x for x in y_test]\n",
    "y_test1= [1 if x==\"DEPRESSED\" else x for x in y_test1]\n",
    "\n",
    "y_pred= [0 if x==\"NORMAL\" else x for x in y_pred]\n",
    "y_pred= [1 if x==\"DEPRESSED\" else x for x in y_pred]\n",
    "\n",
    "print(metrics.accuracy_score(y_test1, y_pred))            #Accuracy\n",
    "print(precision_score(y_test1, y_pred))                   #Precision\n",
    "print(recall_score(y_test1, y_pred))                      #Recall\n",
    "print(f1_score(y_test1, y_pred))                          #F1 Score\n",
    "print(roc_auc_score(y_test1, y_pred))                     #AUC\n",
    "print(matthews_corrcoef(y_test1, y_pred))                 #MCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   DEPRESSED       0.96      0.97      0.96       483\n",
      "      NORMAL       0.97      0.95      0.96       413\n",
      "\n",
      "   micro avg       0.96      0.96      0.96       896\n",
      "   macro avg       0.96      0.96      0.96       896\n",
      "weighted avg       0.96      0.96      0.96       896\n",
      "\n",
      "\n",
      "\n",
      "[[469  14]\n",
      " [ 22 391]]\n",
      "\n",
      "\n",
      "0.9598214285714286\n",
      "0.955193482688391\n",
      "0.9710144927536232\n",
      "0.9630390143737168\n",
      "0.9588728638102256\n",
      "0.9191845266959948\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "clf = XGBClassifier().fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"\\n\")\n",
    "print(metrics.confusion_matrix(y_test, y_pred)) \n",
    "print(\"\\n\")\n",
    "\n",
    "y_test1= [0 if x==\"NORMAL\" else x for x in y_test]\n",
    "y_test1= [1 if x==\"DEPRESSED\" else x for x in y_test1]\n",
    "\n",
    "y_pred= [0 if x==\"NORMAL\" else x for x in y_pred]\n",
    "y_pred= [1 if x==\"DEPRESSED\" else x for x in y_pred]\n",
    "\n",
    "print(metrics.accuracy_score(y_test1, y_pred))            #Accuracy\n",
    "print(precision_score(y_test1, y_pred))                   #Precision\n",
    "print(recall_score(y_test1, y_pred))                      #Recall\n",
    "print(f1_score(y_test1, y_pred))                          #F1 Score\n",
    "print(roc_auc_score(y_test1, y_pred))                     #AUC\n",
    "print(matthews_corrcoef(y_test1, y_pred))                 #MCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   DEPRESSED       0.94      0.96      0.95       483\n",
      "      NORMAL       0.95      0.93      0.94       413\n",
      "\n",
      "   micro avg       0.95      0.95      0.95       896\n",
      "   macro avg       0.95      0.95      0.95       896\n",
      "weighted avg       0.95      0.95      0.95       896\n",
      "\n",
      "\n",
      "\n",
      "[[463  20]\n",
      " [ 27 386]]\n",
      "\n",
      "\n",
      "0.9475446428571429\n",
      "0.9448979591836735\n",
      "0.9585921325051759\n",
      "0.9516957862281602\n",
      "0.9466084149208689\n",
      "0.8944260341524756\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "clf = AdaBoostClassifier().fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"\\n\")\n",
    "print(metrics.confusion_matrix(y_test, y_pred)) \n",
    "print(\"\\n\")\n",
    "\n",
    "y_test1= [0 if x==\"NORMAL\" else x for x in y_test]\n",
    "y_test1= [1 if x==\"DEPRESSED\" else x for x in y_test1]\n",
    "\n",
    "y_pred= [0 if x==\"NORMAL\" else x for x in y_pred]\n",
    "y_pred= [1 if x==\"DEPRESSED\" else x for x in y_pred]\n",
    "\n",
    "print(metrics.accuracy_score(y_test1, y_pred))            #Accuracy\n",
    "print(precision_score(y_test1, y_pred))                   #Precision\n",
    "print(recall_score(y_test1, y_pred))                      #Recall\n",
    "print(f1_score(y_test1, y_pred))                          #F1 Score\n",
    "print(roc_auc_score(y_test1, y_pred))                     #AUC\n",
    "print(matthews_corrcoef(y_test1, y_pred))                 #MCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   DEPRESSED       0.95      0.96      0.96       483\n",
      "      NORMAL       0.96      0.94      0.95       413\n",
      "\n",
      "   micro avg       0.95      0.95      0.95       896\n",
      "   macro avg       0.95      0.95      0.95       896\n",
      "weighted avg       0.95      0.95      0.95       896\n",
      "\n",
      "\n",
      "\n",
      "[[466  17]\n",
      " [ 24 389]]\n",
      "\n",
      "\n",
      "0.9542410714285714\n",
      "0.9510204081632653\n",
      "0.9648033126293996\n",
      "0.9578622816032888\n",
      "0.9533459662420605\n",
      "0.907919378896506\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "clf = BaggingClassifier().fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"\\n\")\n",
    "print(metrics.confusion_matrix(y_test, y_pred)) \n",
    "print(\"\\n\")\n",
    "\n",
    "y_test1= [0 if x==\"NORMAL\" else x for x in y_test]\n",
    "y_test1= [1 if x==\"DEPRESSED\" else x for x in y_test1]\n",
    "\n",
    "y_pred= [0 if x==\"NORMAL\" else x for x in y_pred]\n",
    "y_pred= [1 if x==\"DEPRESSED\" else x for x in y_pred]\n",
    "\n",
    "print(metrics.accuracy_score(y_test1, y_pred))            #Accuracy\n",
    "print(precision_score(y_test1, y_pred))                   #Precision\n",
    "print(recall_score(y_test1, y_pred))                      #Recall\n",
    "print(f1_score(y_test1, y_pred))                          #F1 Score\n",
    "print(roc_auc_score(y_test1, y_pred))                     #AUC\n",
    "print(matthews_corrcoef(y_test1, y_pred))                 #MCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
